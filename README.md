# Human_Action_Recognition
In my human action recognition project, I explored the UCF50 dataset, a collection of realistic action videos from YouTube. To identify the actions within these videos, I compared two deep learning techniques: ConvLSTM and LRCN. ConvLSTM combines convolutional neural networks (CNNs) for capturing spatial features and long short-term memory (LSTM) networks for handling temporal information in video sequences. LRCN, on the other hand, utilizes a convolutional architecture specifically designed for recognizing actions in videos. By evaluating both approaches, I aimed to determine the most effective method for action recognition within the UCF50 dataset.

# Sample Output Video
<video src='' width=180/>
