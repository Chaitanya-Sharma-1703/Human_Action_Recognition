# Human_Action_Recognition
In my human action recognition project, I explored the UCF50 dataset, a collection of realistic action videos from YouTube. To identify the actions within these videos, I compared two deep learning techniques: ConvLSTM and LRCN. ConvLSTM combines convolutional neural networks (CNNs) for capturing spatial features and long short-term memory (LSTM) networks for handling temporal information in video sequences. LRCN, on the other hand, utilizes a convolutional architecture specifically designed for recognizing actions in videos. By evaluating both approaches, I aimed to determine the most effective method for action recognition within the UCF50 dataset.

# Sample Output Video
https://github.com/user-attachments/assets/ef9996e3-293f-4dd9-a233-e4f1dbe1ec18

# Conclusion
In conclusion, this project investigated the effectiveness of ConvLSTM and LRCN approaches for human action recognition using the UCF50 dataset. By evaluating their performance, we can gain valuable insights into the strengths and weaknesses of each technique for this task.
n healthcare, it can be used for patient behavior monitoring, assisting with physical therapy by analyzing movement patterns, or even detecting falls in elderly care facilities. The retail sector could leverage this technology for customer behavior analysis, optimizing store layouts and product placement. Furthermore, the security industry can benefit from action recognition for automated video surveillance, improving threat detection and response times. As this technology continues to evolve, its applications will undoubtedly expand across numerous fields.

